{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b740ebbf-79ba-44e3-af1c-aad0d2fab5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-01-29 02:02:58.562 ip-172-31-22-132:154617 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2023-01-29 02:02:58.721 ip-172-31-22-132:154617 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "sys.path.append('./src')\n",
    "\n",
    "from open_clip import create_model_and_transforms, trace_model, get_tokenizer\n",
    "from open_clip import ClipLoss, get_cast_dtype\n",
    "from training.data import get_data\n",
    "from training.distributed import is_master, init_distributed_device, world_info_from_env\n",
    "from training.logger import setup_logging\n",
    "from training.params import parse_args\n",
    "from training.scheduler import cosine_lr\n",
    "from training.train import train_one_epoch, evaluate\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "import smdebug.pytorch as smd\n",
    "from smdebug.core.reduction_config import ReductionConfig\n",
    "from smdebug.core.save_config import SaveConfig\n",
    "from smdebug.core.collection import CollectionKeys\n",
    "from smdebug.core.config_constants import DEFAULT_CONFIG_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3f4035-4989-42d2-84de-11ec8d60bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_dict = {\n",
    "    \"train_data\": \"pipe:aws s3 cp s3://jbsnyder-sagemaker-us-west-2/data/laion/laion400m/data/{00000..02499}.tar -\",\n",
    "    \"train_num_samples\": 80,\n",
    "    \"val_data\": \"pipe:aws s3 cp s3://jbsnyder-sagemaker-us-west-2/data/laion/laion400m/data/{02500..02587}.tar -\",\n",
    "    \"val_num_samples\": 10000,\n",
    "    \"imagenet_val\": None, # \"pipe:aws s3 cp s3://jbsnyder-sagemaker-us-west-2/data/imagenet/val/val_{0000..0127}.tar -\",\n",
    "    \"imagenet_v2\": None,\n",
    "    \"dataset_type\": \"webdataset\",\n",
    "    \"batch_size\": 16,\n",
    "    \"warmup\": 2000,\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 5e-4,\n",
    "    \"wd\": 0.2,\n",
    "    \"eps\": 1.0e-8,\n",
    "    \"beta1\": 0.9,\n",
    "    \"beta2\": 0.98,\n",
    "    \"precision\": \"amp_bfloat16\",\n",
    "    \"workers\": 4,\n",
    "    \"model\": \"ViT-H-14\",\n",
    "    \"name\": \"proto_1\",\n",
    "    \"pretrained\": \"laion2b_s32b_b79k\", #'laion2b_s34b_b79k', #\"laion400m_e32\",\n",
    "    \"horovod\": False,\n",
    "    \"torchscript\": False,\n",
    "    \"force_quick_gelu\": False,\n",
    "    \"force_custom_text\": False,\n",
    "    \"force_patch_dropout\": None,\n",
    "    \"pretrained_image\": False,\n",
    "    \"image_mean\": None,\n",
    "    \"image_std\": None,\n",
    "    \"use_bn_sync\": True,\n",
    "    \"seed\": 0,\n",
    "    \"accum_freq\": 1,\n",
    "    \"local_loss\": False,\n",
    "    \"gather_with_grad\": False,\n",
    "    \"skip_scheduler\": False,\n",
    "    \"grad_clip_norm\": None,\n",
    "    \"log_every_n_steps\": 100,\n",
    "    \"wandb\": False,\n",
    "    \"log_level\": logging.INFO,\n",
    "    \"log_path\": \"./training_log\",\n",
    "    \"debug\": False,\n",
    "    \"dist_backend\": \"nccl\",\n",
    "    \"dist_url\": \"env://\",\n",
    "    \"no_set_device_rank\": False,\n",
    "    \"ddp_static_graph\": False,\n",
    "    \"val_frequency\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ae69db2-2938-4671-b80f-f25d1a2e961c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/open_clip_env/lib/python3.9/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 802: system not yet initialized (Triggered internally at /opt/conda/conda-bld/pytorch_1670525539683/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-01-29,02:03:00 | INFO | Loaded ViT-H-14 model config.\n",
      "2023-01-29,02:03:09 | INFO | Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "args = Namespace(**arg_dict)\n",
    "\n",
    "args.local_rank, args.rank, args.world_size = world_info_from_env()\n",
    "args.distributed = args.world_size>1\n",
    "\n",
    "args.log_level = logging.DEBUG if args.debug else logging.INFO\n",
    "setup_logging(args.log_path, args.log_level)\n",
    "\n",
    "device = init_distributed_device(args)\n",
    "\n",
    "model, preprocess_train, preprocess_val = create_model_and_transforms(\n",
    "        args.model,\n",
    "        args.pretrained,\n",
    "        precision=args.precision,\n",
    "        device=device,\n",
    "        jit=args.torchscript,\n",
    "        force_quick_gelu=args.force_quick_gelu,\n",
    "        force_custom_text=args.force_custom_text,\n",
    "        force_patch_dropout=args.force_patch_dropout,\n",
    "        pretrained_image=args.pretrained_image,\n",
    "        image_mean=args.image_mean,\n",
    "        image_std=args.image_std,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef22511f-7f20-435b-b37c-3aaa5ade297a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/open_clip_env/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    }
   ],
   "source": [
    "exclude = lambda n, p: p.ndim < 2 or \"bn\" in n or \"ln\" in n or \"bias\" in n or 'logit_scale' in n\n",
    "include = lambda n, p: not exclude(n, p)\n",
    "\n",
    "named_parameters = list(model.named_parameters())\n",
    "gain_or_bias_params = [p for n, p in named_parameters if exclude(n, p) and p.requires_grad]\n",
    "rest_params = [p for n, p in named_parameters if include(n, p) and p.requires_grad]\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    [\n",
    "        {\"params\": gain_or_bias_params, \"weight_decay\": 0.},\n",
    "        {\"params\": rest_params, \"weight_decay\": args.wd},\n",
    "    ],\n",
    "    lr=args.lr,\n",
    "    betas=(args.beta1, args.beta2),\n",
    "    eps=args.eps,\n",
    ")\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "start_epoch = 0\n",
    "data = get_data(args, (preprocess_train, preprocess_val), epoch=start_epoch, tokenizer=get_tokenizer(args.model))\n",
    "\n",
    "total_steps = (data[\"train\"].dataloader.num_batches // args.accum_freq) * args.epochs\n",
    "scheduler = cosine_lr(optimizer, args.lr, args.warmup, total_steps)\n",
    "\n",
    "# evaluate(model, data, start_epoch, args)\n",
    "\n",
    "loss = ClipLoss(\n",
    "        local_loss=args.local_loss,\n",
    "        gather_with_grad=args.gather_with_grad,\n",
    "        cache_labels=True,\n",
    "        rank=args.rank,\n",
    "        world_size=args.world_size,\n",
    "        use_horovod=args.horovod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0586ab9-26c2-4cbc-bfc1-40368f27f657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/open_clip_env/lib/python3.9/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 802: system not yet initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/open_clip/./src/training/train.py:110\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, data, epoch, optimizer, scaler, scheduler, args, loss, tb_writer, debugger_hook)\u001b[0m\n\u001b[1;32m    107\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39maccum_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mautocast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    111\u001b[0m         image_features, text_features, logit_scale \u001b[38;5;241m=\u001b[39m model(images, texts)\n\u001b[1;32m    112\u001b[0m         total_loss \u001b[38;5;241m=\u001b[39m loss(image_features, text_features, logit_scale)\n",
      "File \u001b[0;32m~/open_clip/./src/training/precision.py:10\u001b[0m, in \u001b[0;36mget_autocast.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m precision \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamp_bfloat16\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m precision \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamp_bf16\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# amp_bfloat16 is more stable than amp float16 for clip training\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mamp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautocast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m suppress\n",
      "File \u001b[0;32m/opt/conda/envs/open_clip_env/lib/python3.9/site-packages/torch/cuda/amp/autocast_mode.py:25\u001b[0m, in \u001b[0;36mautocast.__init__\u001b[0;34m(self, enabled, dtype, cache_enabled)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfast_dtype \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_enabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/open_clip_env/lib/python3.9/site-packages/torch/amp/autocast_mode.py:224\u001b[0m, in \u001b[0;36mautocast.__init__\u001b[0;34m(self, device_type, dtype, enabled, cache_enabled)\u001b[0m\n\u001b[1;32m    222\u001b[0m         enabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfast_dtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mbfloat16 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_bf16_supported\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrent CUDA Device does not support bfloat16. Please switch dtype to float16.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enabled \u001b[38;5;241m=\u001b[39m enabled\n",
      "File \u001b[0;32m/opt/conda/envs/open_clip_env/lib/python3.9/site-packages/torch/cuda/__init__.py:102\u001b[0m, in \u001b[0;36mis_bf16_supported\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m     cuda_maj_decide \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_properties(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cuda_maj_decide\n",
      "File \u001b[0;32m/opt/conda/envs/open_clip_env/lib/python3.9/site-packages/torch/cuda/__init__.py:552\u001b[0m, in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_device\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    551\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 552\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[0;32m/opt/conda/envs/open_clip_env/lib/python3.9/site-packages/torch/cuda/__init__.py:229\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    228\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 229\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    233\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 802: system not yet initialized"
     ]
    }
   ],
   "source": [
    "train_one_epoch(model, data, 0, optimizer, scaler, scheduler, args, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80d8a3cc-f865-41a9-9362-b8a8c392b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_optimizer_state(model, optimizer):\n",
    "    '''\n",
    "    For now hardcode abs_min abs_max mean\n",
    "    '''\n",
    "    state_summary = {}\n",
    "    for param_name, param in model.named_parameters():\n",
    "        state_summary[f'{param_name}.optimizer.exp_avg.mean'] = optimizer.state[param]['exp_avg'].mean()\n",
    "        state_summary[f'{param_name}.optimizer.exp_avg.abs_min'] = optimizer.state[param]['exp_avg'].abs().min()\n",
    "        state_summary[f'{param_name}.optimizer.exp_avg.abs_max'] = optimizer.state[param]['exp_avg'].abs().max()\n",
    "        state_summary[f'{param_name}.optimizer.exp_avg_sq.mean'] = optimizer.state[param]['exp_avg_sq'].mean()\n",
    "        state_summary[f'{param_name}.optimizer.exp_avg_sq.abs_min'] = optimizer.state[param]['exp_avg_sq'].abs().min()\n",
    "        state_summary[f'{param_name}.optimizer.exp_avg_sq.abs_max'] = optimizer.state[param]['exp_avg_sq'].abs().max()\n",
    "    return state_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f35c5b3-2b7c-497a-a031-77455f184f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_summary = reduce_optimizer_state(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fb0a239-3b85-4d5c-ad3d-4e74eb44f68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['token_embedding.weight.optimizer.exp_avg.abs_min',\n",
       " 'token_embedding.weight.optimizer.exp_avg_sq.abs_min']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i,j in state_summary.items() if j==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d24112-c2c9-489f-a0ee-224b7f26fb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
